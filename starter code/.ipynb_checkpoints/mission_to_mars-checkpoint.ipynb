{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all():\n",
    "\n",
    "    # Initiate headless driver for deployment\n",
    "    browser = Browser(\"chrome\", executable_path=\"/usr/local/bin/chromedriver\", headless=True)\n",
    "    news_title, news_paragraph = mars_news(browser)\n",
    "\n",
    "    scrape_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser(\"chrome\", executable_path=\"/usr/local/bin/chromedriver\", headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_news(browser):\n",
    "    \n",
    "    # return news_title, news_p\n",
    "    \n",
    "   # browser = init_browser()\n",
    "#     listings = {}\n",
    "    \n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "   # print(soup)\n",
    "    listings[\"news_title\"] = soup.find(\"div\", class_=\"content_title\").get_text()\n",
    "    listings[\"news_p\"] = soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "   \n",
    "    return listings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': 'NASA Seeking Partner in Contest to Name Next Mars Rover',\n",
       " 'news_p': 'NASA has a class assignment for corporations, nonprofits and educational organizations involved in science and space exploration: partner with the agency to inspire future engineers and scientists by sponsoring a contest to name the next rover to venture to the Red Planet.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_news(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16694_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "def featured_image(browser):\n",
    "\n",
    "    # Find and click the full image button\n",
    "    url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    browser.visit(url)\n",
    "    full_image = browser.find_by_id(\"full_image\")\n",
    "    full_image.click()\n",
    "    \n",
    "    #info = browser.find_by_class(\"button\")\n",
    "   # info.click()\n",
    "    browser.is_element_present_by_text('more info', wait_time=1)\n",
    "    \n",
    "    info = browser.find_link_by_partial_text('more info')\n",
    "    info.click()\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #images = soup.find_all('', class_='text')\n",
    "    \n",
    "    #print(soup)\n",
    "    featured_image = soup.find(\"figure\", class_=\"lede\").a[\"href\"]\n",
    "    \n",
    "    link = \"https://www.jpl.nasa.gov\" + featured_image\n",
    "    print(link)\n",
    "    # listings[\"news_p\"] = soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "    \n",
    "    # Use the base url to create an absolute url\n",
    "   \n",
    "\n",
    "    # return img_url\n",
    "\n",
    "featured_image(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jose Morales captured Mars from Chicago last night. 15000 frames for this Mars tonight.  The South Pole, Syrtis Major Planum, and Hellas Planitia are visible.pic.twitter.com/cFkgmdoHDV\n"
     ]
    }
   ],
   "source": [
    "def twitter_weather(browser):\n",
    "    url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #info = browser.find_by_class(\"button\")\n",
    "   # info.click()\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #images = soup.find_all('', class_='text')\n",
    "    \n",
    "    #print(soup)\n",
    "    mars_weather = soup.find(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "    #link = soup.find(\"a\", class_=\"lede\").href\n",
    "    \n",
    "    print(mars_weather)\n",
    "    # listings[\"news_p\"] = soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "    \n",
    "    # Use the base url to create an absolute url\n",
    "   \n",
    "\n",
    "    # return img_url\n",
    "\n",
    "twitter_weather(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Facts\n",
    "\n",
    "#Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "# Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mars_facts():\n",
    "    url = 'http://space-facts.com/mars/'\n",
    "    df = pd.read_html(url)[0]\n",
    "    df.columns=[\"a\",\"b\"]\n",
    "    df.set_index(\"a\",inplace=True)\n",
    "    df\n",
    "    df_html = df.to_html()\n",
    "    df_html\n",
    "mars_facts()\n",
    "\n",
    "       \n",
    "    # Add some bootstrap styling to <table>\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "def hemispheres(browser):\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    hemisphere_image_urls = []\n",
    "    results = soup.find('div', class_='result-list')\n",
    "    items = results.find_all('div', class_='item')\n",
    "    for item in items:\n",
    "        title=[]\n",
    "        result = item.find('div', class_='description')\n",
    "        text = result.a.text\n",
    "        title.append(text)\n",
    "        \n",
    "        url=[]\n",
    "    browser.click_link_by_partial_text('Cerberus Hemisphere Enhanced')\n",
    "        \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "    images1 = soup.find('div', class_='downloads').find('ul').find('li')\n",
    "    image1 = images1.a['href']\n",
    "    url.append(image1)\n",
    "    browser.click_link_by_partial_text('Back')\n",
    "    browser.click_link_by_partial_text('Schiaparelli Hemisphere Enhanced')\n",
    "        \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "    images2 = soup.find('div', class_='downloads').find('ul').find('li')\n",
    "    image2 = images2.a['href']\n",
    "    url.append(image2)\n",
    "    browser.click_link_by_partial_text('Back')\n",
    "    browser.click_link_by_partial_text('Syrtis Major Hemisphere Enhanced')\n",
    "        \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "    images3 = soup.find('div', class_='downloads').find('ul').find('li')\n",
    "    image3 = images3.a['href']\n",
    "    url.append(image3)\n",
    "        \n",
    "    browser.click_link_by_partial_text('Back')\n",
    "    browser.click_link_by_partial_text('Valles Marineris Hemisphere Enhanced')\n",
    "        \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "    images4 = soup.find('div', class_='downloads').find('ul').find('li')\n",
    "    image4 = images4.a['href']\n",
    "    url.append(image4)\n",
    "        \n",
    "    hemisphere_image_urls.append({'title': title[0], 'img_url': url[0]})\n",
    "    print(hemisphere_image_urls)   \n",
    "hemispheres(browser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hemispheres_info.append([{'title': title[0], 'img_url': url[0]},{'title': title[1], 'img_url': url[1]},{'title': title[2], 'img_url': url[2]},{'title': title[3], 'img_url': url[3]}])\n",
    "# print(hemispheres_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
